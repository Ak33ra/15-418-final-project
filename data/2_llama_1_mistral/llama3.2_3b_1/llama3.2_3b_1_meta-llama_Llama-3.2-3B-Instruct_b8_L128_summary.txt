avg_ms=138.67314193725585
p50_ms=138.80831909179688
p90_ms=140.70066833496094
p95_ms=141.20550537109375
p99_ms=142.14962768554688
throughput_tokens_per_s=7384.270563822083
config_model_name=meta-llama/Llama-3.2-3B-Instruct
config_batch_size=8
config_seq_len=128
config_num_warmup=10
config_num_iters=100
config_device=cuda
config_out_dir=data/2_llama_1_mistral/llama3.2_3b_1
config_tag=llama3.2_3b_1
